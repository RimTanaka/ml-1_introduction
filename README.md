## **Kaggle RentHop — Краткое Техническое Задание**

Проект посвящён анализу и прогнозированию стоимости аренды квартир по датасету **RentHop** (Kaggle).  
Цель — построить модели регрессии, провести статистический анализ, выполнить feature engineering и сравнить качество моделей.

---

### **1. Введение**
В ноутбуке необходимо:
- привести **5 примеров применения ML** в жизни и описать их пользу,
- классифицировать задачи по типу (classification, regression, clustering),
- объяснить разницу между **multiclass** и **multilabel**,
- определить, к какому типу относится задача цен (регрессия) и можно ли свести её к классификации.

---

### **2. Загрузка и первичный анализ данных**
- Импортировать: `pandas`, `numpy`, `sklearn`, `lightgbm`, `scipy`, `statsmodels`, `matplotlib`, `seaborn`.
- Загрузить `train.json` с Kaggle.
- Определить размер набора, список колонок, целевую колонку (`price`).
- Выполнить: `info()`, `describe()`, `corr()`, анализ пропусков.
- Создать DataFrame с колонками:  
  `bathrooms`, `bedrooms`, `interest_level`, `price`.

---

### **3. Статистический анализ**
- Построить **гистограмму** и **boxplot** целевой переменной.
- Найти выбросы → удалить строки вне **1–99 перцентилей**.
- Построить обновлённую гистограмму и интерпретировать изменения.

---

### **4. Анализ характеристик**
- Исследовать тип `interest_level`, вывести распределение.
- Закодировать значения (0/1/2).
- Построить гистограммы для `bathrooms` и `bedrooms`, оценить выбросы.

---

### **5. Комплексный анализ**
- Вывести **корреляционную матрицу** и heatmap.
- Построить **scatterplot** (цель → признак) для:
  - `price` vs `bathrooms`
  - `price` vs `bedrooms`
  - `price` vs `interest_level_encoded`

---

### **6. Feature Engineering**
- Добавить примеры новых признаков:  
  `bathrooms_squared`, `bedrooms_squared`, `interest_level_squared`.
- Построить новую корреляционную матрицу.
- Выполнить разбиение на train/test.
- Инициализировать `PolynomialFeatures(degree=10)` и преобразовать признаки.

---

### **7. Обучение моделей**
Необходимо обучить и сравнить 3 модели:

#### **7.1. Linear Regression**
- Обучить модель.
- Посчитать **MAE** и **RMSE** на train/test.
- Сохранить результаты в таблицы:
  - `result_MAE`
  - `result_RMSE`

#### **7.2. Decision Tree Regressor**
- `random_state=21`
- Аналогично рассчитать MAE и RMSE.

#### **7.3. Naive Models**
- Среднее (`mean`) и медиана (`median`) цены.
- Посчитать MAE и RMSE для наивных предсказаний.

---

### **8. Сравнение моделей**
- Вывести таблицы `result_MAE` и `result_RMSE`.
- Определить **лучшую модель**.

---

### **9. Дополнительно**
- Можно использовать весь датасет.
- Создавать новые признаки.
- Пробовать LightGBM, RandomForest, новые фичи и метрики.
